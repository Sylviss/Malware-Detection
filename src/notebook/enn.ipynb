{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Repo\\Malware-Detection\\src\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if not os.path.isdir(\"models\"):\n",
    "    %cd ../\n",
    "else:\n",
    "    print(\"HEHEHE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do for both: binary + multiclass\n",
    "classify_type = \"binary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression,LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, recall_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import joblib as jl\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from skorch import NeuralNetClassifier\n",
    "from sklearn.utils import resample\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = r\"../Datasets/ClaMP_In_Selected.csv\"\n",
    "df = pd.read_csv(datasets)\n",
    "df2 = pd.read_csv(r\"../Datasets/ClaMP_In_Selected_Test.csv\")\n",
    "\n",
    "if classify_type == \"multiclass\":\n",
    "    df3 = pd.read_csv(r\"../Datasets/ClaMP_In_Selected_Additional.csv\")\n",
    "    df = pd.concat([df,df3])\n",
    "df2 = df2.sample(frac = 1)\n",
    "# Seperate the data\n",
    "X_hehe,y = df.drop(columns=[\"class\"]), df[\"class\"].to_numpy(np.float32)\n",
    "X_hehe_2, y_true = df2.drop(columns=[\"class\"]), df2[\"class\"].to_numpy(np.float32)\n",
    "for i,label in enumerate(y):\n",
    "    if label!=0:\n",
    "        y[i]=1\n",
    "for i,label in enumerate(y_true):\n",
    "    if label!=0:\n",
    "        y_true[i]=1\n",
    "ohc = OneHotEncoder()\n",
    "ohc.fit(y.reshape(-1, 1))\n",
    "y_ohe = ohc.transform(y.reshape(-1, 1)).toarray()\n",
    "y_true_ohe = ohc.transform(y_true.reshape(-1, 1)).toarray()\n",
    "out = [\"e_lfanew\", \"NumberOfSections\", \"BaseOfData\", \"SizeOfStackReserve\", \"SizeOfHeapReserve\", \"SizeOfHeapCommit\", \"E_text\", \"E_data\", \"filesize\", \"E_file\"]\n",
    "categories = [sorted(list(set(X_hehe[col]).union(set(X_hehe_2[col])))) for col in X_hehe.columns if col not in out]\n",
    "ohe = OneHotEncoder(categories=categories,handle_unknown=\"ignore\")\n",
    "scaler = StandardScaler()\n",
    "categorical_1 = X_hehe.drop(columns = out).to_numpy()\n",
    "categorical_2 = X_hehe_2.drop(columns = out).to_numpy()\n",
    "non_categorical_1 = X_hehe[out].to_numpy()\n",
    "non_categorical_2 = X_hehe_2[out].to_numpy()\n",
    "scaler.fit(non_categorical_1)\n",
    "trans_non_cate1 = scaler.transform(non_categorical_1)\n",
    "trans_non_cate2 = scaler.transform(non_categorical_2)\n",
    "ohe.fit(categorical_1)\n",
    "trans_cate_1 = ohe.transform(categorical_1).toarray()\n",
    "ohe.fit(categorical_2)\n",
    "trans_cate_2 = ohe.transform(categorical_2).toarray()\n",
    "X = np.concatenate((trans_cate_1, trans_non_cate1), axis = 1)\n",
    "X_true = np.concatenate((trans_cate_2, trans_non_cate2), axis = 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state = 16, test_size = 0.25)\n",
    "X_train, X_test, y_train_ohe, y_test_ohe = train_test_split(X,y_ohe, random_state = 16, test_size = 0.25)\n",
    "X_train = torch.from_numpy(X_train).unsqueeze(1).to(torch.float32)\n",
    "X_test = torch.from_numpy(X_test).unsqueeze(1).to(torch.float32)\n",
    "X_true = torch.from_numpy(X_true).unsqueeze(1).to(torch.float32)\n",
    "y_train_ohe = torch.from_numpy(y_train_ohe).to(torch.float32)\n",
    "y_test_ohe = torch.from_numpy(y_test_ohe).to(torch.float32)\n",
    "y_true_ohe = torch.from_numpy(y_true_ohe).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self,input_dim,hidden_size,num_filter,output_dim,dropout):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1,num_filter,3, padding = 1)\n",
    "        self.conv2 = nn.Conv1d(num_filter,num_filter,3, padding = 1)\n",
    "        self.conv3 = nn.Conv1d(num_filter,num_filter,3, padding = 1)\n",
    "        self.maxpool1 = nn.MaxPool1d(2) \n",
    "        self.maxpool2 = nn.MaxPool1d(3) \n",
    "        self.conv4 = nn.Conv1d(num_filter,num_filter,3, padding = 1)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dense = nn.Linear(int(num_filter*input_dim/6),hidden_size)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.dense2 = nn.Linear(hidden_size,output_dim)\n",
    "        self.prelu = nn.PReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self,X):\n",
    "        X = self.conv1(X)\n",
    "        X = self.prelu(X)\n",
    "        # X = self.conv2(X)\n",
    "        # X = self.prelu(X)\n",
    "        X = self.maxpool1(X)\n",
    "        X = self.conv3(X)\n",
    "        X = self.prelu(X)\n",
    "        # X = self.conv4(X)\n",
    "        # X = self.prelu(X)\n",
    "        X = self.maxpool2(X)\n",
    "        X = self.flatten(X)\n",
    "        X = self.drop(X)\n",
    "        X = self.dense(X)\n",
    "        X = self.prelu(X)\n",
    "        X = self.dense2(X)\n",
    "        X = self.prelu(X)\n",
    "        X = self.softmax(X)\n",
    "        return X\n",
    "    \n",
    "class ANN_1(nn.Module):\n",
    "    def __init__(self,input_dim,hidden_size,output_dim,dropout):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(input_dim,hidden_size)\n",
    "        self.prelu = nn.PReLU()\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.dense2 = nn.Linear(hidden_size,output_dim)\n",
    "        self.max = nn.Softmax(dim=1)\n",
    "    def forward(self,X):\n",
    "        return self.max(self.dense2(self.drop(self.prelu(self.dense(X)))))\n",
    "    \n",
    "class ANN_2(nn.Module):\n",
    "    def __init__(self,input_dim,hidden_size_1,hidden_size_2,output_dim,dropout):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(input_dim,hidden_size_1)\n",
    "        self.dense2 = nn.Linear(hidden_size_1,hidden_size_2)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.prelu = nn.PReLU()\n",
    "        self.dense3 = nn.Linear(hidden_size_2,output_dim)\n",
    "        self.max = nn.Softmax(dim=1)\n",
    "    def forward(self,X):\n",
    "        X = self.dense(X)\n",
    "        X = self.prelu(X)\n",
    "        X = self.drop(X)\n",
    "        X = self.dense2(X)\n",
    "        X = self.prelu(X)\n",
    "        X = self.dense3(X)\n",
    "        X = self.max(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HEHEHEHEHE:\n",
    "    def __init__(self):\n",
    "        self.models = [NeuralNetClassifier(module = CNN,module__input_dim = 198,\n",
    "                                           module__output_dim = 2, module__dropout = 0.4, \n",
    "                                           module__num_filter=48,module__hidden_size=40, max_epochs = 75,\n",
    "                          lr = 0.02, verbose = 0, optimizer = optimizer, \n",
    "                          device = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "                          criterion = nn.BCELoss, train_split=None),\n",
    "                       NeuralNetClassifier(module = CNN,module__input_dim = 198,\n",
    "                                           module__output_dim = 2, module__dropout = 0.4, \n",
    "                                           module__num_filter=32,module__hidden_size=40, max_epochs = 75,\n",
    "                          lr = 0.02, verbose = 0, optimizer = optimizer, \n",
    "                          device = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "                          criterion = nn.BCELoss, train_split=None),\n",
    "                       NeuralNetClassifier(module = CNN,module__input_dim = 198,\n",
    "                                           module__output_dim = 2, module__dropout = 0.4, \n",
    "                                           module__num_filter=48,module__hidden_size=20, max_epochs = 75,\n",
    "                          lr = 0.02, verbose = 0, optimizer = optimizer, \n",
    "                          device = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "                          criterion = nn.BCELoss, train_split=None),\n",
    "                       NeuralNetClassifier(module = ANN_1,module__input_dim = 198,\n",
    "                                           module__output_dim = 2, module__dropout = 0.3,\n",
    "                                           module__hidden_size=90, max_epochs = 75,\n",
    "                          lr = 0.1, verbose = 0, optimizer = optimizer, \n",
    "                          device = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "                          criterion = nn.BCELoss, train_split=None),\n",
    "                       NeuralNetClassifier(module = ANN_1,module__input_dim = 198,\n",
    "                                           module__output_dim = 2, module__dropout = 0.3,\n",
    "                                           module__hidden_size=70, max_epochs = 75,\n",
    "                          lr = 0.1, verbose = 0, optimizer = optimizer, \n",
    "                          device = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "                          criterion = nn.BCELoss, train_split=None),\n",
    "                       NeuralNetClassifier(module = ANN_2,module__input_dim = 198,\n",
    "                                           module__output_dim = 2, module__dropout = 0.3, \n",
    "                                           module__hidden_size_1=70,module__hidden_size_2=70, max_epochs = 75 ,\n",
    "                          lr = 0.1, verbose = 0, optimizer = optimizer, \n",
    "                          device = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "                          criterion = nn.BCELoss, train_split=None),\n",
    "                       NeuralNetClassifier(module = ANN_2,module__input_dim = 198,\n",
    "                                           module__output_dim = 2, module__dropout = 0.3, \n",
    "                                           module__hidden_size_1=50,module__hidden_size_2=50, max_epochs = 75 ,\n",
    "                          lr = 0.1, verbose = 0, optimizer = optimizer, \n",
    "                          device = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "                          criterion = nn.BCELoss, train_split=None),\n",
    "                       NeuralNetClassifier(module = ANN_2,module__input_dim = 198,\n",
    "                                           module__output_dim = 2, module__dropout = 0.3, \n",
    "                                           module__hidden_size_1=70,module__hidden_size_2=50, max_epochs = 75 ,\n",
    "                          lr = 0.1, verbose = 0, optimizer = optimizer, \n",
    "                          device = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "                          criterion = nn.BCELoss, train_split=None)\n",
    "                       ]\n",
    "        self.second_stage = RandomForestClassifier()\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        hehe=[]\n",
    "        for a in tqdm(range(8)):\n",
    "            if(a<3):\n",
    "                self.models[a].fit(X_train,y_train)\n",
    "                y_train_pred = self.models[a].predict(X_train)\n",
    "                hehe.append(y_train_pred)\n",
    "            else:\n",
    "                X_hehehe=X_train.squeeze()\n",
    "                self.models[a].fit(X_hehehe,y_train)\n",
    "                y_train_pred = self.models[a].predict(X_hehehe)\n",
    "                hehe.append(y_train_pred)\n",
    "        y_super_train = np.array([0 if y_train[a][0]>y_train[a][1] else 1 for a in range(len(y_train))])\n",
    "        X_second_stage = np.array([[0 if hehe[a][b][0]>hehe[a][b][1] else 1 for a in range(8)] for b in range(len(hehe[0]))])\n",
    "        self.second_stage.fit(X_second_stage,y_super_train)\n",
    "\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        res = []\n",
    "        for a in range(8):\n",
    "            if a<3:\n",
    "                res.append(self.models[a].predict(X_test))\n",
    "            else:\n",
    "                X_hehehe=X_test.squeeze()\n",
    "                res.append(self.models[a].predict(X_hehehe))\n",
    "        # res2 = []\n",
    "        # for a in range(len(res[0])):\n",
    "        #     res2.append([0,0])\n",
    "        #     for b in range(8):\n",
    "        #         res2[-1][0]+=res[b][a][0]\n",
    "        #         res2[-1][1]+=res[b][a][1]\n",
    "        #     if res2[-1][1]>=res2[-1][0]:\n",
    "        #         res2[-1]=1\n",
    "        #     else:\n",
    "        #         res2[-1]=0\n",
    "        \n",
    "        X_second_stage =np.array([[0 if res[a][b][0]>res[a][b][1] else 1 for a in range(8)] for b in range(len(res[0]))])\n",
    "        res2 = self.second_stage.predict(X_second_stage)\n",
    "        return np.array(res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = HEHEHEHEHE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada.fit(X_train,y_train_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_train=ada.predict(X_train)\n",
    "y_predict=ada.predict(X_test)\n",
    "y_pred_true = ada.predict(X_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics :\n",
      "\tAccuracy: 0.9905298182748912\n",
      "\tRecall: 0.9936554416788678\n",
      "\tF1: 0.9909953760038939\n",
      "Test metrics :\n",
      "\tAccuracy: 0.9815809669992326\n",
      "\tRecall: 0.9881129271916791\n",
      "\tF1: 0.982274741506647\n",
      "True Test metrics :\n",
      "\tAccuracy: 0.9157427937915743\n",
      "\tRecall: 0.896969696969697\n",
      "\tF1: 0.8862275449101796\n"
     ]
    }
   ],
   "source": [
    "display_labels = {\"binary\":[\"Benign\",\"Malware\"],\"multiclass\":[\"benign\",\"generic\",\"virus\",\"ransomware\",\"rat\",\"spyware\",\"worm\"]}\n",
    "print(\"Train metrics :\")\n",
    "print(\"\\tAccuracy:\", accuracy_score(y_train, y_predict_train))\n",
    "if classify_type == \"binary\":\n",
    "    print(\"\\tRecall:\", recall_score(y_train, y_predict_train))\n",
    "    print(\"\\tF1:\",f1_score(y_train, y_predict_train))\n",
    "print(\"Test metrics :\")\n",
    "print(\"\\tAccuracy:\", accuracy_score(y_test, y_predict))\n",
    "if classify_type == \"binary\":\n",
    "    print(\"\\tRecall:\", recall_score(y_test, y_predict))\n",
    "    print(\"\\tF1:\",f1_score(y_test, y_predict))\n",
    "print(\"True Test metrics :\")\n",
    "print(\"\\tAccuracy:\", accuracy_score(y_true, y_pred_true))\n",
    "if classify_type == \"binary\":\n",
    "    print(\"\\tRecall:\", recall_score(y_true, y_pred_true))\n",
    "    print(\"\\tF1:\",f1_score(y_true, y_pred_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo: Save the models you trained into models folder, using joblib/pickle.\n",
    "# Only save the binary one.\n",
    "# if classify_type == \"binary\":\n",
    "#     import joblib\n",
    "#     joblib.dump(ada, 'models/ENN.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
