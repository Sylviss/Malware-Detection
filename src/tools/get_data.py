import os, pickle, joblib
from torch import nn
from sklearn.preprocessing import StandardScaler,OneHotEncoder
import lightgbm as lgb
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression,LinearRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, recall_score
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sb
import joblib as jl
from tqdm import tqdm
import numpy as np
from torch import nn
from skorch import NeuralNetClassifier
from sklearn.utils import resample
import torch
from tools.input import input_single_file_3
def get_model(model_str):
    match model_str:
        case 'Random Forest':
            return joblib.load("./models/RandomForestClassifier.joblib")
        case "LightGBM":
            return joblib.load("./models/LGBClassifier.joblib")
        case "Support Vector Machine":
            return joblib.load("./models/SVMClassifier.joblib")
        case "K-Nearest Neighbors":
            return joblib.load("./models/KNeightborsClassifier.joblib")
        case "Logistic Regression":
            return joblib.load("./models/LogisticRegression.joblib")
        case "Decision Tree":
            return joblib.load("./models/DecisionTreeClassifier.joblib")
        case "AdaBoost":
            return joblib.load("./models/AdaBoostClassifier.joblib")
        case "1 Layer Neural Network":
            from notebook.ann_1 import ann_1
            return ann_1()
        case "2 Layer Neural Network":
            from notebook.ann_2 import ann_2
            return ann_2()
        case "Convolutional Neural Network":
            from notebook.cnn import cnn
            return cnn()
        case "Ensemble Neural Network":
            from notebook.enn import enn
            return enn()
        
hehehehehehehehehehe = {0: "Benign", 1: "Malware"}        
        
def get_output(model,type,path):
    res = input_single_file_3(path)
    for name in res:
        data = pd.DataFrame(data=res[name]["pe_header"],index = [0])
        match type:
            case 1:
                scaler = joblib.load("./tools/ScalerClassic.joblib")
                data_new = scaler.transform(data)
                prediction = model.predict(data_new)
                return hehehehehehehehehehe[prediction[0]]
            case 2:
                scaler = joblib.load("./tools/ScalerOhe.joblib")
                ohe = joblib.load("./tools/OheOhe.joblib")
                out = ["e_lfanew", "NumberOfSections", "BaseOfData", "SizeOfStackReserve", "SizeOfHeapReserve", "SizeOfHeapCommit", "E_text", "E_data", "filesize", "E_file"]
                categorical = data.drop(columns = out).to_numpy()
                non_categorical = data[out].to_numpy()
                trans_non_cate = scaler.transform(non_categorical)
                trans_cate = ohe.transform(categorical).toarray()
                data_new = np.concatenate((trans_cate, trans_non_cate), axis = 1)
                prediction = model.predict(data_new)
                return hehehehehehehehehehe[prediction[0]]
            case 3:
                scaler = joblib.load("./tools/ScalerOhe.joblib")
                ohe = joblib.load("./tools/OheOhe.joblib")
                out = ["e_lfanew", "NumberOfSections", "BaseOfData", "SizeOfStackReserve", "SizeOfHeapReserve", "SizeOfHeapCommit", "E_text", "E_data", "filesize", "E_file"]
                categorical = data.drop(columns = out).to_numpy()
                non_categorical = data[out].to_numpy()
                trans_non_cate = scaler.transform(non_categorical)
                trans_cate = ohe.transform(categorical).toarray()
                data_new = torch.tensor(np.concatenate((trans_cate, trans_non_cate), axis = 1),dtype=torch.float32)
                prediction = model.predict(data_new)
                return hehehehehehehehehehe[prediction[0]]
            case 4:
                scaler = joblib.load("./tools/ScalerOhe.joblib")
                ohe = joblib.load("./tools/OheOhe.joblib")
                ohc = OneHotEncoder()
                ohc.fit(np.array([0,1]).reshape(-1,1))
                out = ["e_lfanew", "NumberOfSections", "BaseOfData", "SizeOfStackReserve", "SizeOfHeapReserve", "SizeOfHeapCommit", "E_text", "E_data", "filesize", "E_file"]
                categorical = data.drop(columns = out).to_numpy()
                non_categorical = data[out].to_numpy()
                trans_non_cate = scaler.transform(non_categorical)
                trans_cate = ohe.transform(categorical).toarray()
                data_new = torch.tensor(np.concatenate((trans_cate, trans_non_cate), axis = 1),dtype=torch.float32).unsqueeze(1)
                prediction = model.predict(data_new)
                return hehehehehehehehehehe[ohc.inverse_transform(prediction)[0][0]]
            case 5:
                scaler = joblib.load("./tools/ScalerOhe.joblib")
                ohe = joblib.load("./tools/OheOhe.joblib")
                ohc = OneHotEncoder()
                ohc.fit(np.array([0,1]).reshape(-1,1))
                out = ["e_lfanew", "NumberOfSections", "BaseOfData", "SizeOfStackReserve", "SizeOfHeapReserve", "SizeOfHeapCommit", "E_text", "E_data", "filesize", "E_file"]
                categorical = data.drop(columns = out).to_numpy()
                non_categorical = data[out].to_numpy()
                trans_non_cate = scaler.transform(non_categorical)
                trans_cate = ohe.transform(categorical).toarray()
                data_new = torch.tensor(np.concatenate((trans_cate, trans_non_cate), axis = 1),dtype=torch.float32).unsqueeze(1)
                prediction = model.predict(data_new)
                return hehehehehehehehehehe[prediction[0]]
            case _:
                raise Exception("Invalid type")
    