from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import OneHotEncoder
from sklearn.model_selection import train_test_split
import numpy as np
import pandas as pd
import torch

def data_split(classify_type):
    datasets = r"../Datasets/ClaMP_In_Selected.csv"
    df = pd.read_csv(datasets)
    df2 = pd.read_csv(r"../Datasets/ClaMP_In_Selected_Test.csv")
    df2 = df2.sample(frac = 1)
    # Seperate the data
    X_hehe,y = df.drop(columns=["class"]), df["class"].to_numpy()
    X_hehe_2, y_true = df2.drop(columns=["class"]), df2["class"].to_numpy()

    if classify_type == "binary":
        for i,label in enumerate(y):
            if label!=0:
                y[i]=1
        for i,label in enumerate(y_true):
            if label!=0:
                y_true[i]=1
    return X_hehe, y, X_hehe_2, y_true
            
def data_preprocess_basic(classify_type,seed):
    X_hehe, y, X_hehe_2, y_true = data_split(classify_type)
    scaler = StandardScaler()
    scaler.fit(X_hehe)
    X = scaler.transform(X_hehe)
    X_true = scaler.transform(X_hehe_2)
    X_train, X_test, y_train, y_test = train_test_split(X,y, random_state = seed, test_size = 0.25)
    X_true, X_valid, y_true, y_valid = train_test_split(X_true,y_true, random_state = seed, test_size = 0.25)
    return X_train, X_test, y_train, y_test, X_true, X_valid, y_true, y_valid

def data_preprocess_ohe(classify_type,seed):
    X_hehe, y, X_hehe_2, y_true = data_split(classify_type)
    out = ["e_lfanew", "NumberOfSections", "BaseOfData", "SizeOfStackReserve", "SizeOfHeapReserve", "SizeOfHeapCommit", "E_text", "E_data", "filesize", "E_file"]
    scaler = StandardScaler()
    categories = [sorted(list(set(X_hehe[col]).union(set(X_hehe_2[col])))) for col in X_hehe.columns if col not in out]
    ohe = OneHotEncoder(categories=categories)
    categorical_1 = X_hehe.drop(columns = out).to_numpy()
    categorical_2 = X_hehe_2.drop(columns = out).to_numpy()
    non_categorical_1 = X_hehe[out].to_numpy()
    non_categorical_2 = X_hehe_2[out].to_numpy()
    scaler.fit(np.concatenate((non_categorical_1, non_categorical_2), axis = 0))
    trans_non_cate1 = scaler.transform(non_categorical_1)
    trans_non_cate2 = scaler.transform(non_categorical_2)
    ohe.fit(categorical_1)
    trans_cate_1 = ohe.transform(categorical_1).toarray()
    ohe.fit(categorical_2)
    trans_cate_2 = ohe.transform(categorical_2).toarray()
    X = np.concatenate((trans_cate_1, trans_non_cate1), axis = 1)
    X_true = np.concatenate((trans_cate_2, trans_non_cate2), axis = 1)
    X_train, X_test, y_train, y_test = train_test_split(X,y, random_state = seed, test_size = 0.25)
    X_true, X_valid, y_true, y_valid = train_test_split(X_true,y_true, random_state = seed, test_size = 0.25)
    return X_train, X_test, y_train, y_test, X_true, X_valid, y_true, y_valid

def data_process_cnn(classify_type,seed):
    datasets = r"../Datasets/ClaMP_In_Selected.csv"
    df = pd.read_csv(datasets)
    df2 = pd.read_csv(r"../Datasets/ClaMP_In_Selected_Test.csv")
    df2 = df2.sample(frac = 1)
    # Seperate the data
    X_hehe,y = df.drop(columns=["class"]), df["class"].to_numpy(np.float32)
    X_hehe_2, y_true = df2.drop(columns=["class"]), df2["class"].to_numpy(np.float32)
    for i,label in enumerate(y):
        if label!=0:
            y[i]=1
    for i,label in enumerate(y_true):
        if label!=0:
            y_true[i]=1
    ohc = OneHotEncoder()
    ohc.fit(y.reshape(-1, 1))
    y_ohe = ohc.transform(y.reshape(-1, 1)).toarray()
    y_true_ohe = ohc.transform(y_true.reshape(-1, 1)).toarray()
    out = ["e_lfanew", "NumberOfSections", "BaseOfData", "SizeOfStackReserve", "SizeOfHeapReserve", "SizeOfHeapCommit", "E_text", "E_data", "filesize", "E_file"]
    categories = [sorted(list(set(X_hehe[col]).union(set(X_hehe_2[col])))) for col in X_hehe.columns if col not in out]
    ohe = OneHotEncoder(categories=categories,handle_unknown="ignore")
    scaler = StandardScaler()
    categorical_1 = X_hehe.drop(columns = out).to_numpy()
    categorical_2 = X_hehe_2.drop(columns = out).to_numpy()
    non_categorical_1 = X_hehe[out].to_numpy()
    non_categorical_2 = X_hehe_2[out].to_numpy()
    scaler.fit(non_categorical_1)
    trans_non_cate1 = scaler.transform(non_categorical_1)
    trans_non_cate2 = scaler.transform(non_categorical_2)
    ohe.fit(categorical_1)
    trans_cate_1 = ohe.transform(categorical_1).toarray()
    ohe.fit(categorical_2)
    trans_cate_2 = ohe.transform(categorical_2).toarray()
    X = np.concatenate((trans_cate_1, trans_non_cate1), axis = 1)
    X_true_hehe = np.concatenate((trans_cate_2, trans_non_cate2), axis = 1)
    X_train, X_test, y_train, y_test = train_test_split(X,y, random_state = 16, test_size = 0.25)
    X_train, X_test, y_train_ohe, y_test_ohe = train_test_split(X,y_ohe, random_state = 16, test_size = 0.25)
    X_true, X_valid, y_true, y_valid = train_test_split(X_true_hehe,y_true, random_state = 16, test_size = 0.25)
    X_true, X_valid, y_true_ohe, y_valid_ohe = train_test_split(X_true_hehe,y_true_ohe, random_state = 16, test_size = 0.25)
    X_train = torch.from_numpy(X_train).unsqueeze(1).to(torch.float32)
    X_test = torch.from_numpy(X_test).unsqueeze(1).to(torch.float32)
    X_true = torch.from_numpy(X_true).unsqueeze(1).to(torch.float32)
    X_valid = torch.from_numpy(X_valid).unsqueeze(1).to(torch.float32)
    y_train_ohe = torch.from_numpy(y_train_ohe).to(torch.float32)
    y_test_ohe = torch.from_numpy(y_test_ohe).to(torch.float32)
    y_true_ohe = torch.from_numpy(y_true_ohe).to(torch.float32)
    y_valid_ohe = torch.from_numpy(y_valid).to(torch.float32)
    return X_train, X_test, y_train_ohe, y_test_ohe, X_true, X_valid, y_true_ohe, y_valid_ohe, ohc